# Brain-Computer Interface for VR Simulation Reaction Classification

## Overview
This repository contains the code and documentation for a cutting-edge project in the field of Brain-Computer Interfaces (BCI). Our project focuses on capturing and analyzing brain signals from users immersed in a Virtual Reality (VR) simulation. The primary objective is to develop a robust machine learning framework that can classify different types of user reactions within the VR environment.

## Project Description
### Background
Brain-Computer Interfaces represent a significant advancement in understanding human-computer interaction. By tapping into brain signals, we can glean insights into users' cognitive and emotional states. This project leverages these insights to understand user reactions within a VR simulation.

### Methodology
1. **Data Collection**: Brain signals were recorded while users were engaged in a VR simulation. Note: Due to privacy concerns, the dataset is not included in this repository.

2. **Pre-processing**: The raw brain signals underwent a thorough pre-processing phase to enhance signal quality and remove noise.

3. **Feature Extraction**: Key features were extracted from the processed signals to capture the essence of different reactions.

4. **Machine Learning**: We developed a machine learning algorithm to classify these reactions into four distinct categories based on the signal features.

### Reactions Classified
The project successfully classifies four types of reactions, offering a nuanced understanding of user responses in VR environments.

## Technologies Used
- Matlab and Mathwork tools/libraries
- For recording the signals a setup was designed for transfering the data by Bluetooth from the Near-infrared spectroscopy (NIR) system to the computer/mobile 

## License
Matlab License 2022a
